<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="neural networks, feature construction, tile coding, coarse coding, feed-forward architecture, activation functions, deep networks, gradient, online setting, offline setting, representation">

<title>Constructing Features for Prediction – Notes on Reinfocement Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-594d21605a7b9fb32547fedacd8fc358.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d396125c57f3f0defba792e7b0e7a5dc.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background: /images/banner_black_3.jpg;
      }
</style>
<script>
MathJax = {
  loader: {
    load: ['[tex]/boldsymbol']
  },
  tex: {
    tags: "all",
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    packages: {
      '[+]': ['boldsymbol']
    }
  }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Notes on Reinfocement Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Constructing Features for Prediction</h1>
            <p class="subtitle lead">Prediction and Control with Function Approximation</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">Prediction and Control with Function Approximation</div>
                <div class="quarto-category">Reinforcement Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Tuesday, April 2, 2024</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>neural networks, feature construction, tile coding, coarse coding, feed-forward architecture, activation functions, deep networks, gradient, online setting, offline setting, representation</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/logo.png" class="img-fluid figure-img"></p>
<figcaption>RL logo</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/alg_selector.png" class="img-fluid figure-img" data-group="slides"></p>
<figcaption>RL algorithms</figcaption>
</figure>
</div></div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Readings
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><span class="citation" data-cites="sutton2018reinforcement">[@sutton2018reinforcement§9.4-9.5.0, pp. 204-210]</span> <a href="http://incompleteideas.net/book/RLbook2020.pdf#page=194">book</a></label></li>
<li><label><input type="checkbox" checked=""><span class="citation" data-cites="sutton2018reinforcement">[@sutton2018reinforcement§9.5.3-9.5.4, pp. 215-222]</span> <a href="http://incompleteideas.net/book/RLbook2020.pdf#page=194">book</a></label></li>
<li><label><input type="checkbox" checked=""><span class="citation" data-cites="sutton2018reinforcement">[@sutton2018reinforcement§9.7, pp. 223-228]</span> <a href="http://incompleteideas.net/book/RLbook2020.pdf#page=194">book</a></label></li>
</ul>
</div>
</div>
</div>
<p>We discussed methods for representing large, an possibly continuous state spaces. Ways to construct features. A representation is an agent’s internal encoding of the state, the agent constructs features to summarize the current input. Whenever we are talking about features and representation learning, we are in the land of function approximation.</p>
</section>
<section id="lesson-1-feature-construction-for-linear-methods" class="level1 page-columns page-full">
<h1>Lesson 1: Feature Construction for Linear Methods</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><em>Define</em> the difference between <strong>coarse coding</strong> and tabular representations <a href="#sec-l1g1">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Explain</em> the trade-off when designing representations between discrimination and generalization <a href="#sec-l1g2">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> how different coarse coding schemes affect the functions that can be represented <a href="#sec-l1g3">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Explain</em> how tile coding is a (computationally?) convenient case of coarse coding <a href="#sec-l1g4">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Describe</em> how designing the tilings affects the resultant representation <a href="#sec-l1g5">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> that tile coding is a computationally efficient implementation of coarse coding <a href="#sec-l1g6">#</a></label></li>
</ul>
</div>
</div>
<section id="coarse-coding-video" class="level2">
<h2 class="anchored" data-anchor-id="coarse-coding-video">Coarse Coding (Video)</h2>
<p>In this video, Adam White introduces the concept of <strong>coarse coding</strong>, covering the first learning objective of this lesson.</p>
<p>Coarse coding are a way to represent states in a more general way than tabular representations. This allows for generalization across states. The trade-off is that the representation is less discriminative.</p>
</section>
<section id="sec-l1g1" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l1g1">The difference between <strong>coarse coding</strong> and tabular representations</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-coding_states.png" class="img-fluid figure-img"></p>
<figcaption>approximation</figcaption>
</figure>
</div></div><p>Recall that linear function approximation are paramertized by a weight vector <span class="math inline">\mathbf{w}</span> and a feature vector <span class="math inline">\mathbf{x}(s)</span>.</p>
<p>As we saw in the previous unit tabular representations associates one feature per state, this is called a one-hot encoding of the state space.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-tabular_coding.png" class="img-fluid figure-img"></p>
<figcaption>one hot coding</figcaption>
</figure>
</div></div><p>We associate one hot encoding with an indicator function <span class="math inline">\delta_{ij}(s)</span>. This is a very discriminative representation but it does generalize.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-state-aggregation.png" class="img-fluid figure-img"></p>
<figcaption>state aggregation</figcaption>
</figure>
</div></div><p>We also discussed using <strong>state aggregation</strong> for the 1000 state random walk example. In state aggregation we break the continuous state space into discrete regions and associate a feature with each region. This is a more general representation than tabular representations but less discriminative.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-coarse-coding.png" class="img-fluid figure-img"></p>
<figcaption>coarse coding</figcaption>
</figure>
</div></div><p><strong>Coarse coding</strong> uses multiple overlapping shapes to represent states. This is a more General representation than state aggregation but less discriminative. Features are the circles they are in. If the circles overlap, we can have items that are in multiple circles. I.e. they are characterized by multiple features. In the example shown there can be from one to three active features.</p>
<p>So the difference is that tabular representations are one hot encodings while coarse coding uses membership in multiple overlapping shapes to represent states.</p>
<p>How does coarse coding relates to state aggregation?</p>
<p>Coarse coding is also a generalization of state aggregation. In state aggregation we break the state space into discrete regions and associate a feature with each region. But we don’t let these regions overlap. In coarse coding we allow the regions to overlap which can give greater generalization as regions can share features.</p>
<p>In this video the term Reception Field is used to describe the region of the state space that a feature is associated with. This is an idea that comes from CNNs.</p>
</section>
<section id="generalization-properties-of-coarse-coding-video" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="generalization-properties-of-coarse-coding-video">Generalization Properties of Coarse Coding (Video)</h2>
<p>In this video Martha White discusses the generalization properties of coarse coding.</p>
<p>She looks at using small overlapping 1-d intervals to represent a 1-d function.</p>
<p>We see that changing shape size and number of effects the generalization properties of the representation.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-scale-generalization.png" class="img-fluid figure-img"></p>
<figcaption>scale</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-shape-generalization.png" class="img-fluid figure-img"></p>
<figcaption>shape</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-shape-discrimination.png" class="img-fluid figure-img"></p>
<figcaption>discrimination</figcaption>
</figure>
</div></div>

<p>Next we looked at using short interval vs longer intervals to approximate a 1-d function. We see that the longer intervals give a smoother approximation.</p>
</section>
<section id="sec-l1g2" class="level2">
<h2 class="anchored" data-anchor-id="sec-l1g2">The trade-off between discrimination and generalization</h2>
</section>
<section id="tile-coding-video" class="level2">
<h2 class="anchored" data-anchor-id="tile-coding-video">Tile Coding (Video)</h2>
<p>In this video, Martha White introduces the concept of <strong>tile coding</strong>. This is simply a implementation of coarse coding using multiple overlapping grids.</p>
</section>
<section id="sec-l1g4" class="level2">
<h2 class="anchored" data-anchor-id="sec-l1g4">Explain how tile coding is a (computationally?) convenient case of coarse coding</h2>
<p>Tile coding is a computationally efficient implementation of coarse coding. We use multiple overlapping tilings to represent states. Each tiling is a grid of tiles. Each tile is a feature.</p>
<p>If we use one tiling we get state aggregation. If we use multiple tilings we get coarse coding. One tiling means we don’t discriminate between states that are in the same tile. Multiple tilings means we can discriminate between states that are in the same tile in one tiling but not in another.</p>
</section>
<section id="sec-l1g5" class="level2">
<h2 class="anchored" data-anchor-id="sec-l1g5">Describe how designing the tilings affects the resultant representation</h2>
<p>The textbook goes into some more details about how we can generalize using tile coding - using regular tilings generates in a diagonal pattern. Using random tilings generates more spherical regions.</p>
<p>However we also saw that the number size and shape of the tiles affects the generalization properties of the representation. And that increasing the overlap between the tiles an increase the discrimination properties of the representation.</p>
</section>
<section id="sec-l1g6" class="level2">
<h2 class="anchored" data-anchor-id="sec-l1g6"><em>Understand</em> that tile coding is a computationally efficient implementation of coarse coding</h2>
<p>Tile coding is a computationally efficient implementation of coarse coding. Since grids are uniform it is easy to compute which cells a state is in. A second reason is that end up with a sparse representations thus the dot product is just the sum of the weights of the active features for each state.</p>
<p>One caveat is that in high dimensional spaces we end up an exponential number of features. This is called the curse of dimensionality.</p>
</section>
<section id="using-tile-coding-in-td-video" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="using-tile-coding-in-td-video">Using Tile Coding in TD (Video)</h2>
<p>In this video, Adam White shows how to use tile coding in TD learning. He goes back to the 1000 state random walk example and shows how to use tile coding to approximate the value function. We end up needing six tiles.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-tile-coding-performance.png" class="img-fluid figure-img"></p>
<figcaption>tile coding v.s. state aggregation</figcaption>
</figure>
</div></div></section>
<section id="feature-construction-for-linear-methods" class="level2">
<h2 class="anchored" data-anchor-id="feature-construction-for-linear-methods">Feature Construction for Linear Methods</h2>
<p>In the textbook we see two forms of features for linear methods that are not covered in the videos.</p>
<p>The first are polynomials. We might use polynomials features for the state to represent the state space. This seems to be a good for problems where RL is dealing to a greater extent with interpolation or regression.</p>
<p>The following is given as an example of a polynomial feature representation of the state space. It took a bit of time to understand what was going on here.</p>
<p>They explain about the different combination of two features <span class="math inline">s_1</span> and <span class="math inline">s_2</span> doesn’t cover some edge cases but using four <span class="math inline">(1,s_1,s_2,s_1s_2)</span> covers all the possible combinations of the two features. We might also want to include higher powers of the atoms and that is what the polynomial representation is doing.</p>
<p><span class="math display">
x_i(s) = \prod_{j=1}^k s_j^{c_{ij}}
</span></p>
<p>It important to point out that we are not using the polynomials as a function approximation basis function. What we are talking about is a formulation of multinomial from a set of fixed numbers <span class="math inline">s_1 \lsots s_k</span> I.e. we are talking about all the possible products product from powers of these atoms.</p>
<p>The second are Fourier bases.</p>
<p><span class="math display">
x_i(s) = \cos\left(\frac{2\pi s^T a_i}{b}\right)
</span></p>
<p>The book mentions that the Fourier basis is particularly useful for periodic functions.</p>
<p>There are many other orthogonal bases used as functnio expansions that could be used, as features for linear function approximation.</p>
<ul>
<li>Walsh functions and Haar wavelets have discrete support and are used in signal processing.</li>
<li>Legendre polynomials are used in physics.</li>
<li>Chebyshev polynomials are used in numerical analysis.</li>
</ul>
</section>
<section id="other-forms-of-coarse-coding" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="other-forms-of-coarse-coding">Other Forms of Coarse Coding</h2>
<p>In the textbook we see that there are other forms of coarse coding.</p>
<p>For example in section 9.5.5 we see using radial basis functions.</p>
<dl>
<dt>An RBF</dt>
<dd>
is a real-valued function whose value depends only on the distance between the input and a fixed point (called the center). &nbsp;
</dd>
</dl>
<p>Visualizing - Imagine a hill or bump centered at a specific point. The height of the hill at any other point depends solely on its distance from the center. The hill gets flatter as you move away from the cente</p>
<div class="page-columns page-full"><p> <span class="math display">
x_i(s) = \exp\left(-\frac{\|s-c_i\|^2}{2\sigma_i^2}\right)
</span></p><div class="no-row-height column-margin column-container"><img src="rl-radial-basis-functions.png" class="img-fluid" alt="one dimensional radial basis functions"></div></div>
<ul>
<li>Where</li>
<li><span class="math inline">c_i</span> is the center of the radial basis function and</li>
<li><span class="math inline">\sigma_i</span> is the width.</li>
</ul>
<p>This is a form of coarse coding where the features are the distance from a set of centers. This is a more general representation than tile coding but less discriminative. The advantage of RBFs over tiles is that they are approximate functions that vary smoothly and are differentiable. However it appears there is both a computational cost and no real advantage in having continuous/differential features according to the book.</p>
<div id="cell-fig-radial-basis-functions" class="cell page-columns page-full" data-fig.height="3" data-fig.width="3" data-execution_count="1">

<div class="no-row-height column-margin column-container"><div class="cell-output cell-output-display">
<div id="fig-radial-basis-functions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-radial-basis-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="c3-w2_files/figure-html/fig-radial-basis-functions-output-1.png" width="662" height="470" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-radial-basis-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: One-dimensional radial basis functions with centers at -2, 0, and 2.
</figcaption>
</figure>
</div>
</div></div></div>
<p>I find this a bit disappointing as it seems like a nice intermediate step between linear function approximation with its convergence guarantees and neural networks which have no such guarantees.</p>
</section>
</section>
<section id="lesson-2-neural-networks" class="level1 page-columns page-full">
<h1>Lesson 2: Neural Networks</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><em>Define</em> a neural network <a href="#sec-l2g1">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Define</em> activation functions <a href="#sec-l2g2">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Define</em> a feed-forward architecture <a href="#sec-l2g3">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> how neural networks are doing feature construction <a href="#sec-l2g4">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> how neural networks are a non-linear function of state <a href="#sec-l2g5">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> how deep networks are a composition of layers <a href="#sec-l2g6">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> the tradeoff between learning capacity and challenges presented by deeper networks <a href="#sec-l2g7">#</a></label></li>
</ul>
</div>
</div>
<section id="what-is-a-neural-network-video" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-neural-network-video">What is a Neural Network? (Video)</h2>
<p>In this video, Martha White introduces the concept of a neural network. We look at a simple one layer feed forward neural network. Where the <span class="math inline">output=f(sW)</span> is a non-linear function of the input.</p>
</section>
<section id="sec-l2g1" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l2g1">Define a neural network</h2>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="img/rl-feedforward-nn.png" class="img-fluid"></div></div>
<p>A Neural network consists of a network of nodes which process and pass on information.</p>
<ul>
<li>The circles are the noes</li>
<li>The lines are the connections</li>
<li>The nodes are organized in layers</li>
</ul>
<p>Data starts at the input layer. It is passed through the connections to the hidden layer. The hidden layer is preforms some computation on the data and passes it to the output layer. This process repeats until the last layer produces the output of the network.</p>
</section>
<section id="deep-neural-networks-video" class="level2">
<h2 class="anchored" data-anchor-id="deep-neural-networks-video">Deep Neural Networks (Video)</h2>
<p>In this video, Martha White introduces the concept of neural networks with multiple hidden layers and activation functions.</p>
</section>
<section id="neural-networks-mechanics" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-mechanics">Neural Networks Mechanics</h2>
<p>A node in the network is a function</p>
<p><span class="math display">
output = f[(w_1 \times input_1) + (w_2 \times input_2) + \ldots + (w_n \times input_n) + b]
</span></p>
<ul>
<li>where:
<ul>
<li><span class="math inline">w_i</span> are the weights,</li>
<li><span class="math inline">input_i</span> are the inputs, and</li>
<li><span class="math inline">b</span> is the bias.</li>
<li><span class="math inline">f</span> is the activation function.</li>
</ul></li>
</ul>
<p>The sum of the product of the weights and inputs is a linear operation. The activation function <span class="math inline">f</span> is where a non-linearity is introduced into the network.</p>
</section>
<section id="sec-l2g2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l2g2">Define activation functions</h2>
<p>Activation functions are non-linear functions that are applied to the output of a node. They introduce non-linearity into the network.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-activation-functions-tanh.png" class="img-fluid figure-img"></p>
<figcaption>tanh activation</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-activation-functions-relu.png" class="img-fluid figure-img"></p>
<figcaption>rectified linear activation function</figcaption>
</figure>
</div></div>
<p>Martha White also mentions threshold activation functions. However these are not used in practice as they are not differentiable. There is some work since this course came out on compressing neural networks to use threshold activation functions which are easy to compute on a CPU as matrix multiplication becomes a series of comparisons. However these are trained with a differentiable approximation of the threshold function and then quantized to the threshold function.</p>
</section>
<section id="the-neural-network-implementation" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-neural-network-implementation">The Neural Network Implementation</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-nn-implementation.png" class="img-fluid figure-img"></p>
<figcaption>Neural Network Implementation</figcaption>
</figure>
</div></div><p>A neural network is a parameterized function that is a composition of linear and non-linear functions. It is a function of the state. The linear functions are the weights and the non-linear functions are the activation functions. The weights are learned from data.</p>
</section>
<section id="sec-l2g3" class="level2">
<h2 class="anchored" data-anchor-id="sec-l2g3">Define a feed-forward architecture</h2>
<p>A feed forward architecture is a neural network where the connections between nodes do not form a cycle. The data flows from the input layer to the output layer.</p>
<p>An example of a non-feed forward architecture is a recurrent neural network where the connections between nodes form cycles.</p>
</section>
<section id="non-linear-approximation-with-neural-networks-video" class="level2">
<h2 class="anchored" data-anchor-id="non-linear-approximation-with-neural-networks-video">Non-linear Approximation with Neural Networks (video)</h2>
</section>
<section id="sec-l2g4" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l2g4">How Neural Networks are doing feature construction</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-activation-1.png" class="img-fluid figure-img"></p>
<figcaption>neural feature 1</figcaption>
</figure>
</div>
<p>darker means greater activation for the feature</p>
</div><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-activation-2.png" class="img-fluid figure-img"></p>
<figcaption>neural feature 2</figcaption>
</figure>
</div>
<p>the one generalize differently</p>
</div></div>
<p>We construct a non-linear function of the state using a neural network.</p>
<p>recall A node takes the form</p>
<p><span class="math display">
output = f[(w_1 \times input_1) + \ldots + (w_n \times input_n) + b]
</span></p>
<p>We call this output of the node a feature! We can see that these features are a non-linear function of the inputs. We repeat this process until we evaluate all the nodes of the final layer. And the output of this final layer is called the representation.</p>
<p>Note: This is not very different from tile coding where we pass input to a tile coder and get back a new representation of the state.</p>
<p>In both cases we are constructing a non-linear mapping of the input of the features. And we take a nonlinear function of the representation to form the output - a nonlinear approximation of the state.</p>
<p>Recall that in tile coding we had to set some hyper-parameters: size shape of tiles + number of tiling. These are fixed before training. In a neural network we also have hyperparameters for the size of the layers, the number of layers, the activation functions. These too are fixed before training.</p>
<p>The difference is that Neural networks have weights that get updated during training. But tile coding does not change during training.</p>
</section>
<section id="sec-l2g5" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l2g5">How neural networks are a non-linear function of state</h2>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rl-activation-3.png" class="img-fluid figure-img"></p>
<figcaption>neural feature 3</figcaption>
</figure>
</div>
<p>there are no hard boundaries</p>
</div><div class="">
<p><img src="rl-activation-4.png" class="img-fluid" alt="neural feature 4"> this shows how it generelises</p>
</div></div>
<p>Neural networks are non linear functions of the because of the non-linear nature of the activation functions. These are applied recursively as we move to the final layer.</p>
</section>
<section id="deep-neural-networks-video-1" class="level2">
<h2 class="anchored" data-anchor-id="deep-neural-networks-video-1">Deep Neural Networks (Video)</h2>
</section>
<section id="sec-l2g6" class="level2">
<h2 class="anchored" data-anchor-id="sec-l2g6">How deep networks are a composition of layers</h2>
<p>Neural networks are modular. We can add or remove layers. Each layer is a function of the previous layer. The output of the previous layer is the input to the next layer.</p>
<p>Depth allows composition of features. Each layer can learn a different representation of the input. The final layer can learn a representation of the input that is a composition of the representations learned by the previous layers</p>
<p>We can design the network to remove undesirable features. For example we can design a network with a bottleneck that has less features than the input. This forces the network to learn a compressed representation of the input.</p>
</section>
<section id="sec-l2g7" class="level2">
<h2 class="anchored" data-anchor-id="sec-l2g7">The tradeoff between learning capacity and challenges presented by deeper networks</h2>
<p>Depth can increase the learning capacity of the network by allowing the network to learn complex compositions and abstractions. However, deeper networks are harder to train.</p>
</section>
</section>
<section id="lesson-3-training-neural-networks" class="level1 page-columns page-full">
<h1>Lesson 3: Training Neural Networks</h1>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><em>Compute</em> the gradient for a single hidden layer neural network <a href="#sec-l3g1">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> how to compute the gradient for arbitrarily deep networks <a href="#sec-l3g2">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Understand</em> the importance of initialization for neural networks <a href="#sec-l3g3">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Describe</em> strategies for initializing neural networks <a href="#sec-l3g4">#</a></label></li>
<li><label><input type="checkbox" checked=""><em>Describe</em> optimization techniques for training neural networks <a href="#sec-l3g5">#</a></label></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Discussion prompt
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>What properties of the representation are important for our online setting? This contrasts the offline, batch setting.</p>
</blockquote>
</div>
</div>
<section id="gradient-descent-for-training-neural-networks-video" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="gradient-descent-for-training-neural-networks-video">Gradient Descent for Training Neural Networks (Video)</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="nn-notation.png" class="img-fluid"></p>
</div></div><p>If we use the square error loss then</p>
<p><span id="eq-loss"><span class="math display">
L(\hat y_k,y_k) = (\hat y_k-y_k)^2 \qquad
\tag{1}</span></span></p>
<p><span class="math display">
A = A −αδ^As
</span></p>
<p><span class="math display">
B = B −αδ^Bx
</span></p>
<p>Let’s start at the output of the network and work backwards. Recall: <span class="math display">
x = f_A(sA)
</span></p>
<p><span class="math display">
\hat{y} = f_B(xB)
</span></p>
<p>We start by taking the partial derivative of the loss function with respect to the first set of weights B.</p>
<p>We use the chain rule given the derivative of L with respect to <span class="math inline">\hat{Y} \times \frac{∂\hat{y}}{∂B}</span>. The next step is again to use the chain rule for this derivative.</p>
<p><span class="math display">
\frac{∂L(\hat{y}_k,y_k)}{∂B_{jk}} = \frac {∂L(\hat{y}_k,y_k)}{∂\hat{y}_k} \frac{∂\hat{y}_k}{∂B_{jk}}
</span></p>
<p>let’s introduce a new variable, θ where θ is the output of the hidden layer times the last set of weights.</p>
<p><span class="math display">
θ \dot = xB
</span></p>
<p>Thus</p>
<p><span class="math display">
\hat y \dot = f_B(θ)
</span></p>
<p>Rewriting we have:</p>
<p><span class="math display">
\frac{∂L(\hat{y}_k,y_k)}{∂B_{jk}} = \frac {∂L(\hat{y}_k,y_k)}{∂\hat{y}_k} \frac{∂f_B(\theta_k)}{∂\theta} \frac{∂\theta_k}{∂B_{jk}}
</span></p>
<p>and since</p>
<p><span class="math display">
\frac{∂\theta_k}{∂B_{jk}} = x_j
</span></p>
<p><span class="math display">
\frac{∂L(\hat{y}_k,y_k)}{∂B_{jk}} = \frac {∂L(\hat{y}_k,y_k)}{∂\hat{y}_k} \frac{∂f_B(\theta_k)}{∂\theta} x_j
</span></p>
<p>now that we calculated the gradient for the last layer we can move to the previous layer.</p>
<p>we use</p>
<p><span class="math display">
\Psi \dot =  sA
</span></p>
<p>and</p>
<p><span class="math display">
x \dot = f_A(\Psi)
</span></p>
<p><span class="math display">
\begin{aligned}
\frac{∂L(\hat{y}_k,y_k)}{∂A_{ij}} &amp;= \delta_k^B \frac {∂\theta_k}{∂A_{ij}} \newline
&amp; = \delta_k^B B_{jk} \frac {∂x_j}{∂A_{ij}} \newline
  &amp; = \delta_k^B B_{jk} \frac {∂f_A(\Psi_j)}{∂\Psi_j} \frac {∂\Psi_j}{∂A_{ij}}
\end{aligned}
</span></p>
<p>since</p>
<p><span class="math display">
\frac {∂\Psi_j}{∂A_{ij}} = s_{ij}
</span></p>
<p>we have</p>
<p><span class="math display">
\frac{∂L(\hat{y}_k,y_k)}{∂A_{ij}} = \delta_k^B B_{jk} \frac {∂f_A(\Psi_j)}{∂\Psi_j} s_{ij}
</span></p>
<p>We can clean up this derivative by again, defining a term <span class="math inline">δ_A</span>.</p>
<p><span class="math display">
δ^A_j = (B_{jk}δ^B_k ) \frac{∂f_A(ψ_j)}{∂ψ_j}
</span></p>
<p>The final result will be:</p>
<p><span class="math display">
\frac{∂L(\hat{y}_k,y_k)}{∂A_{ij}}= δ^A_j s_i
</span></p>
<p>Obtaining as a final result for both gradients the next expressions</p>
<p><span class="math display">
\frac {∂L(\hat{y}_k,y_k)}{∂B_{jk}} = δ^B_k x_j
</span></p>
</section>
<section id="sec-l3g1" class="level2">
<h2 class="anchored" data-anchor-id="sec-l3g1">Computing the Gradient for a Single Hidden Layer Neural Network</h2>
<p>Let’s summerize the results:</p>
<p><span class="math display">
\frac {∂L(\hat{y}_k,y_k)}{∂B_{jk}} = δ^B_k x_j \qquad
\frac{∂L(\hat{y}_k,y_k)}{∂A_{ij}}= δ^A_j s_i
</span></p>
<p>where:</p>
<p><span class="math display">
δ^B_k = \frac {∂L(\hat{y}_k,y_k)}{∂\hat{y}_k} \frac{∂f_B(\theta_k)}{∂\theta} \qquad
δ^A_j = (B_{jk}δ^B_k ) \frac{∂f_A(ψ_j)}{∂ψ_j}
</span></p>
</section>
<section id="sec-l3g2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l3g2">Computing the Gradient for Arbitrarily Deep Networks</h2>

<div class="no-row-height column-margin column-container"><div id="fig-gradient-descent-pseudo-code" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gradient-descent-pseudo-code-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn-backpop.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gradient-descent-pseudo-code-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Gradient Descent Pseudo-code
</figcaption>
</figure>
</div><div id="fig-gradient-descent-RELU" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gradient-descent-RELU-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/nn-backpop-relu.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gradient-descent-RELU-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Gradient Descent Pseudo-code for RELU
</figcaption>
</figure>
</div></div>
<p>Now that we have estimated the gradient for a hidden layer neural network. We can use it to learn to optimize the weights of the network by updating the weights to minimize the error in the loss function in the direction of the negative gradient.</p>
<p>The <a href="#fig-gradient-descent-pseudo-code">pseudocode in the figure</a> outlines how to implementing the backprop algorithm with Stochastic gradient descent.</p>
<p>For each data point s, y in our dataset, we first get our prediction <span class="math inline">\hat{y}</span> from the network. This is the forward pass. Then we can estimate the loss using the actual value <span class="math inline">y</span></p>
<p>Next we compute the gradients starting from the output. We first compute <span class="math inline">δ^B</span> and the gradient for <span class="math inline">B</span>, then we use this gradient to update the parameters <span class="math inline">B</span>, with the step size <span class="math inline">α_B</span> for the last layer.</p>
<p>Next, we update the parameters <span class="math inline">A</span>. We compute <span class="math inline">δ^A</span> which reuses <span class="math inline">δ^B</span>.</p>
<p>Notice, that by computing the gradients of the end of the network first, we avoid recomputing the same terms for A, that were already computed for <span class="math inline">δB</span>. We then compute the gradient for A and update A with this gradient using step size <span class="math inline">α_A</span>.</p>
<hr>
<p>Next we look at how we adapt the <a href="#fig-fig-gradient-descent-RELU">pseudocode</a> to work with the ReLU activation on the hidden layer and a linear unit for the output.</p>
<p>First, we compute the error for the output layer, then we compute the derivative of the ReLU units with respect to <span class="math inline">\Psi</span>, and finally, we use the aerial signal from the output layer along with you to compute the air signal for the hidden layer, the rest remains the same</p>
</section>
<section id="optimization-strategies-for-nns-video" class="level2">
<h2 class="anchored" data-anchor-id="optimization-strategies-for-nns-video">Optimization Strategies for NNs (Video)</h2>
</section>
<section id="sec-l3g3" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l3g3">The Importance of Initialization for Neural Networks</h2>
<p>One simple yet effective initialization strategy for the weights, is to randomly sample the initial weights from a normal distribution with small variance Fig. 42. This way, each neuron has a different output from other neurons within its layer. This provides a more diverse set of potential features.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rl-feedforward-nn.png" class="img-fluid figure-img"></p>
<figcaption>Weights initialization</figcaption>
</figure>
</div></div><p>By keeping the variants small, we ensure that the output of each neuron is within the same range as its neighbors. One downside to this strategy is that, as we add more inputs to a neuron, the variance of the output grows.</p>
</section>
<section id="sec-l3g4" class="level2">
<h2 class="anchored" data-anchor-id="sec-l3g4">Strategies for Initializing Neural Networks</h2>
<p><span class="math display">
W_{init} ~ N(0,1)
</span></p>
<p><span class="math display">
W_{init} ~ \frac{N(0,1)}{\sqrt{n_{in}}}
</span></p>
</section>
<section id="sec-l3g5" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-l3g5">Optimization Techniques for Training Neural Networks</h2>
<ul>
<li>momentum update AKA heavy ball method <span class="math display">
W_{t+1} ← W_t −α∇_wL(W_t) + λM_t
</span></li>
</ul>
<p><span class="math display">
M_{t+1} = λM_t −α∇_wL
</span></p>
<p>vector step size adaptation</p>
<ul>
<li>separate step size for each weight</li>
</ul>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><img src="nn-vector-step-size.png" class="img-fluid"></div></div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/orenbochman\.github\.io\/notes-rl\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>